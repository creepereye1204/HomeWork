{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝 라이브러리 설치\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화 라이브러리 설치\n",
    "!pip install  plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝 관련 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow.keras.optimizers.schedules as schedules#학습률 스케줄링 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "epochs=100\n",
    "rootPath=\"../input/plant-pathology-2020-fgvc7/\"\n",
    "images= \"images/\"\n",
    "test= \"test.csv\"\n",
    "train = \"train.csv\"\n",
    "result = \"sample_submission.csv\"\n",
    "\n",
    "submission = pd.read_csv(rootPath+result)\n",
    "testData = pd.read_csv(rootPath+test)\n",
    "trainData = pd.read_csv(rootPath+train)\n",
    "plusData=pd.read_csv(\"/kaggle/input/reallabel/plus.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터불러오는 함수\n",
    "def originPath(name):\n",
    "    return rootPath + 'images/' + name + '.jpg'\n",
    "#추가 데이터불러오는 함수\n",
    "def plusPath(name):\n",
    "    return \"../input/plusimg/\" + name + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터불러오는코드\n",
    "testPaths = testData.image_id.apply(originPath).values\n",
    "trainPaths = trainData.image_id.apply(originPath).values\n",
    "plusPaths = plusData.image_id.apply(plusPath).values\n",
    "trainLabels = np.float32(trainData.loc[:, 'healthy':'scab'].values)\n",
    "plusLabels = np.float32(plusData.loc[:, 'healthy':'scab'].values)\n",
    "trainPaths, validPaths, trainLabels, validLabels =train_test_split(trainPaths, trainLabels, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원래데이터에 추가 데이터 합치기\n",
    "trainLabels=np.concatenate((trainLabels,plusLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원래데이터 경로에 추가경로 합치기\n",
    "trainPaths=np.concatenate((trainPaths,plusPaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2048 1365 3 데이터의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1365//4#데이터가 큼으로 비율대로 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=341\n",
    "width=514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def dataPreprocessing(filename, label=None, image_size=(width, height)):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    if label is None:\n",
    "        return image\n",
    "    return image, label\n",
    "    \n",
    "#데이터 증가 함수\n",
    "def dataAugment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if label is None:    \n",
    "        return image\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPU설정\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "#TPU상태에따른 바치사이즈 조정\n",
    "batchSize = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 불러옴\n",
    "trainDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((trainPaths, trainLabels))\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .map(dataAugment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(batchSize)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((validPaths, validLabels))\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .batch(batchSize)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "testDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(testPaths)\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .batch(batchSize)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9가지 모델에대한 여러가지 학습 스케줄 알고리즘과 옵티마이저 조합으로 위한 전략패턴사용 여기서 최소 9*4*4*30번 이상의 학습을 수행함 \n",
    "from tensorflow.keras.models import clone_model\n",
    "class Combination():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "        self.optimizer=None\n",
    "    \n",
    "    def setModel(self,Model):\n",
    "        model=Model\n",
    "        self.model=model.getModel()\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def setOptimizer(self,Optimizer):\n",
    "        \n",
    "        self.optimizer=Optimizer\n",
    "        print(self.optimizer)\n",
    "    \n",
    "    \n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "        \n",
    "    \n",
    "    def onLearning(self,epochs=30):\n",
    "        \n",
    "        with strategy.scope(): \n",
    "            self.model.compile(optimizer=self.optimizer,\n",
    "                          loss = 'categorical_crossentropy',\n",
    "                          metrics=['categorical_accuracy'])\n",
    "        \n",
    "        stepPerEpoch = trainLabels.shape[0] // batchSize\n",
    "        history = self.model.fit(\n",
    "                    trainDataset,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=stepPerEpoch,\n",
    "                    validation_data=validDataset)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(filename, label=None, image_size=(512, 512)):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    if label is None:\n",
    "        return image\n",
    "    return image, label\n",
    "    \n",
    "\n",
    "def dataAugment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if label is None:    \n",
    "        return image\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPU설정 \n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "#TPU상태에따른 바치사이즈 조정\n",
    "batchSize = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 불러옴\n",
    "trainDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((trainPaths, trainLabels))\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .map(dataAugment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(batchSize)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((validPaths, validLabels))\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .batch(batchSize)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "testDataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(testPaths)\n",
    "    .map(dataPreprocessing, num_parallel_calls=AUTO)\n",
    "    .batch(batchSize)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9가지 모델에대한 여러가지 학습 스케줄 알고리즘과 옵티마이저 조합으로 위한 전략패턴사용!! 여기서 최소 9*4*4*30번 이상의 학습을 수행함\n",
    "from tensorflow.keras.models import clone_model\n",
    "class Combination():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "        self.optimizer=None\n",
    "    \n",
    "    def setModel(self,Model):\n",
    "        model=Model\n",
    "        self.model=model.getModel()\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def setOptimizer(self,Optimizer):\n",
    "        \n",
    "        self.optimizer=Optimizer\n",
    "        print(self.optimizer)\n",
    "    \n",
    "    \n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "        \n",
    "    \n",
    "    def onLearning(self,epochs=30):\n",
    "        \n",
    "        with strategy.scope(): \n",
    "            self.model.compile(optimizer=self.optimizer,\n",
    "                          loss = 'categorical_crossentropy',\n",
    "                          metrics=['categorical_accuracy'])\n",
    "        \n",
    "        stepPerEpoch = trainLabels.shape[0] // batchSize\n",
    "        history = self.model.fit(\n",
    "                    trainDataset,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=stepPerEpoch,\n",
    "                    validation_data=validDataset)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getModel():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getOptimizer():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오기\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "#처음에는 디폴트로 512*512로 이미지 잘라서 사용, 모든 모델 구성을 동일하게 함(옵티마이저나 학습률 알고리즘을 고정시켯다는게 아님!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([VGG16(input_shape=(width, height, 3),\n",
    "                                                      weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax',kernel_initializer='he_normal')])#이모델에 relu가 사용됨으로 이 가중치 초기화도 시도했다고 강조\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg19(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([VGG19(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inceptionv3(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([InceptionV3(\n",
    "                                                    weights=\"imagenet\",\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet50(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet101(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet101(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet152(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet152(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50v2(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet50V2(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet101v2(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet101V2(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet152v2(Model):\n",
    "    def __init__(self):\n",
    "        with strategy.scope():    \n",
    "            self.Model=tf.keras.Sequential([ResNet152V2(input_shape=(width, height, 3),\n",
    "                                                    weights='imagenet',\n",
    "                                                    include_top=False),\n",
    "                                        L.GlobalAveragePooling2D(),\n",
    "                                        L.Dropout(0.2),\n",
    "                                        L.Dense(trainLabels.shape[1],\n",
    "                                                activation='softmax')])\n",
    "        \n",
    "    def getModel(self):\n",
    "        return self.Model\n",
    "#여기서 Resnet v2 는 renet 업글버전임 참고 https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/rv1_vs_rv2.png 요곳도 넣어줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def setSchedules(self,schedules):    \n",
    "        self.Optim=tf.keras.optimizers.SGD(momentum=0.9,learning_rate=schedules)\n",
    "        return self.Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad(Optimizer):\n",
    "    def setSchedules(self,schedules):    \n",
    "        self.Optim=tf.keras.optimizers.Adagrad(epsilon=1e-6,learning_rate=schedules)\n",
    "        return self.Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop(Optimizer):\n",
    "    def setSchedules(self,schedules):    \n",
    "        self.Optim=tf.keras.optimizers.RMSprop(rho=0.9, epsilon=1e-06,learning_rate=schedules)\n",
    "        return self.Optim\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def setSchedules(self,schedules):    \n",
    "        self.Optim=tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999,learning_rate=schedules)\n",
    "        return self.Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\"Vgg16\":Vgg16(),\"Vgg19\":Vgg19(),\"Resnet50\":Resnet50(),\"Inceptionv3\":Inceptionv3(),\n",
    "        \"Resnet101\":Resnet101(),\"Resnet152\":Resnet152(),\"Resnet50v2\"\\\n",
    "        :Resnet50v2(),\"Resnet101v2\":Resnet101v2(),\"Resnet152v2\":Resnet152v2()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이거 발표할때 까먹을거 같음 \n",
    "#옵티마이저 역할이랑 하이퍼파라미터계수 의미 적어줘\n",
    "optimizers={\"SGD\":SGD(),\"Adagrad\":Adagrad(),\"RMSprop\":RMSprop(),\"Adam\":Adam()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이것도\n",
    "learningRateSchedulers={\"CosineDecay\":schedules.CosineDecay(initial_learning_rate=0.001, decay_steps=1000, alpha=0.0)\\\n",
    "                       ,\"CosineDecayRestarts\":schedules.CosineDecayRestarts(initial_learning_rate=0.001, t_mul=2.0,m_mul=1.0,first_decay_steps=1000, alpha=0.001)\\\n",
    "                       ,\"ExponentialDecay\":schedules.ExponentialDecay(initial_learning_rate=0.01,decay_steps=50,decay_rate=0.96,staircase=True)\\\n",
    "                       ,\"InverseTimeDecay\":schedules.InverseTimeDecay(initial_learning_rate = 0.01,decay_steps = 1.0,decay_rate = 0.5)\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination=Combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프함수\n",
    "def display(training, validation, title,yTitle,epochs):     \n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=np.arange(1, epochs+1), mode='lines+markers', y=training, marker=dict(color=\"#dc143c\"),name=\"Train\"))\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=np.arange(1, epochs+1), mode='lines+markers', y=validation, marker=dict(color=\"#0080ff\"),\n",
    "                   name=\"Validation\"))\n",
    "\n",
    "        fig.update_layout(title_text=title, yaxis_title=yTitle, xaxis_title=\"Epochs\", template=\"plotly_dark\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 함수\n",
    "def performanceCheck():\n",
    "    for modelName,model in models.items():\n",
    "        weights=model.getModel().get_weights()#<- 가중치가 이어서 학습하면 안됨 가중치 초기화\n",
    "        for optimizerName,optimizer in optimizers.items():\n",
    "            for learningRateSchedulerName,learningRateScheduler in learningRateSchedulers.items():\n",
    "                model.getModel().set_weights(weights)\n",
    "                combination.setModel(model)\n",
    "                combination.setOptimizer(optimizer.setSchedules(learningRateScheduler))\n",
    "                history=combination.onLearning(epochs=30)\n",
    "                trainAcc=history.history['categorical_accuracy']\n",
    "                evalAcc=history.history['val_categorical_accuracy']\n",
    "                trainLoss=history.history['loss']\n",
    "                evalLoss=history.history['val_loss']\n",
    "                title=modelName+\" \"+optimizerName+\" \"+learningRateSchedulerName+\" \"\n",
    "                display(trainAcc,evalAcc,title+\"Accuracy\",\"Accuracy\")\n",
    "                display(trainLoss,evalLoss,title+\"Loss\",\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
